\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{natbib}
\usepackage{hyperref}

\usepackage{listings}
\usepackage{rotating, graphicx}
\graphicspath{{./}, {./image/}}
\usepackage{booktabs, natbib}
% \usepackage{breakurl}
% \usepackage [english]{babel}
\usepackage{amsmath, amsbsy, amsthm, epsfig, epsf, psfrag, graphicx, 
amssymb, enumerate}
\usepackage{bm}
\usepackage{multirow, multicol}

\usepackage[dvipsnames]{xcolor}
\definecolor{darkblue}{rgb}{0.1, 0.2, 0.6}


\newcommand{\jy}[1]{\textcolor{orange}{JY: #1}}
\newcommand{\eds}[1]{\textcolor{blue}{(EDS: #1)}}
\newcommand{\of}[1]{\textcolor{purple}{(OF: #1)}}

\sloppy

% \usepackage{csquotes}
% \usepackage [autostyle, english = american]{csquotes}
% \MakeOuterQuote{"}

% \usepackage{bibentry}
\newenvironment{comment}%
{\begin{quotation}\noindent\small\it\color{darkblue}\ignorespaces%
}{\end{quotation}}


\begin{document}

\begin{center}
  {\Large\bf TAS-23-296: Response to the Comments}
\end{center}

We extend our gratitude to the Editor and Associate Editor for 
granting us the opportunity to revise this manuscript. We also want to
express our appreciation to the reviewers for their valuable comments. 


The manuscript has been revised accordingly with the most notable change being 
the addition of new data in both the GLMM and rank comparison sections in an
attempt to expand the scope of the analysis and derive better insights. 


Point-by-point responses to the comments are as follows, with the
comments quoted in \emph{\color{darkblue} italic and blue}.



\subsection*{To Associate Editor}

\begin{comment}
I encourage you to consider the issues raised by the reviewers carefully. I have
little additional material to add, other than to emphasize the need to
re-organize the manuscript to more clearly identify the key goals of the work at
the start, and to provide a more concise and focused presentation of the key
findings.
\end{comment}

Thank you for your feedback. We have carefully addressed the
reviewers' comments and taken additional steps to streamline the
manuscript, focusing on a clearer presentation of the key goals and
findings from the outset. We appreciate your time and consideration in
re-evaluating our submission.


\subsection*{To Reviewer 1}

\begin{comment}
Using Devon Allen's disqualification at the 2022 World Track and Field
championships as a hook, this paper poses two questions. First, were reaction
times at the 2022 World Track and Field Championships faster than they had been
earlier in 2022 national-level competitions, the 2019 World Track and Field
Championships, and the 2023 World Track and Field Championships? Second, based
on modeled reaction times, is the current standard of a 0.1 second threshold
for reaction times before disqualification too conservative? To
address the first point, the paper relies on descriptive statistics, ranked
tests, and the results of a set of GLMMs. The descriptive data analysis lends
credence to the authors' argument that the reaction times at the 2022 World
Championships was faster than at any of the relevant comparisons. The rank test
appears to be set up correctly and I believe the authors are interpreting the
results correctly. Similarly, I believe the GLMM results are arrived at
correctly given the provided code.

The paper attempts to answer the second question by applying the GLMMs they
already fit. To do so, it presents simulations from the fitted GLMM. It then
uses the simulated results to estimate the probability of observing reaction
times below a set of thresholds. I think it does a good job of contextualizing
these in terms of the number of races per an occurrence.
\end{comment}

We thank the reviewer for the accurate summary of our contributions
and these encouraging comments.  


\begin{comment}
However, I do believe the analysis to answer this first question could be
substantially improved. First, the paper only presents results for men running
the 110 meter hurdles. Women also competed at these events as they later
acknowledge in the discussion section. Why not use data from those competitors?
(There is a suggestion that the systematic effect seen at the 2022 World
Championships for men would not/did not appear for women because they may have
slower reaction times. No analysis is provided to support that though. Could
that be provided?) Similarly, other sprinting events were held using the same
block-sensor technology. Were similar patterns present in the 100-meter and
200-meter dashes? What about in the longer 400-meter dash and 400-meter hurdle
races? I think expanding the sample here would yield helpful insights into the
systematic nature of the problem the paper is trying to investigate. These
expanded samples could improve both the ranked-test results and the GLMM results
and improve the generalizability of the conclusions.
\end{comment}


Thank you for the valuable suggestions. We have extended our analysis
by including data from both men's and women's 100-meter dash. This was
justified by a GLMM fit to these data and the event type was not found
to be significantly different in reaction time.


We also considered including additional sprinting events such as the
200-meter dash; however, in a GLMM fit to an expanded dataset that
additionally included 200-meter, the event type effect became
significant. Subsequent pairwise comparisons using Tukey’s Honest
Significant Difference (HSD) test revealed a p-value of 0.0021 when
comparing the reaction times of the 200-meter dash and the 110-meter
hurdles, and a p-value of 0.000017 when comparing the 100-meter dash
and the 200-meter dash. These results indicate that reaction times in
the 200-meter dash are significantly slower, suggesting that this
event does not align well with our focus on extreme reaction times.
Consequently, we decided to exclude the 200-meter data from our
primary analysis.


This difference in reaction times is not unexpected, however, as athletes 
competing in longer sprint
events, such as the 200-meter dash, may not prioritize reaction time
as highly as those specializing in shorter sprints like the 100-meter
dash. While it is common for amateur and collegiate athletes to
compete across multiple sprint distances, elite athletes at the World
Championship level may not exhibit equally strong performances in all
sprint events. Our study aims to evaluate the probability of observing
extreme reaction times, particularly in the context of the 0.1-second
threshold. Including data from events with systematically slower
reaction times would artificially inflate the extremity of a
0.1-second reaction time, potentially biasing our conclusions.


In the revision, we have added explanation about why 100-meter dash
data for both men and wemen were included, while 200-meter dash data
were not included in our analysis in Section~???, paragraph~???.
The subsequent analyses in the manuscript have been updated with the
expanded dataset that included both men and women's 100-meter dash
data; see updated results in Sections~???.
\eds{let's revisit this again after objective 2 analyses are set}


\begin{comment}
Relatedly, I believe the GLMM results could be improved by considering a few
more factors. Currently, the GLMMs regress reaction time onto models that only
contains predictors for year and whether or not an observation comes from a
preliminary heat or a final (both as random intercepts). It strikes me that the
authors may also want to account for confounding factors such as the overall
speed-level of the heat (especially relative to that point in time) and the
speed of the given runner relative to the others in the heat, as these factors
are likely to inform whether a runner tries to push their reaction to the limit
or not and are potentially correlated with year and race type, biasing the
results. Accounting for these additional features (in addition to expanding the
analysis) should help clarify if there was a specific difference attributable to
2022.
\end{comment} 


We apologize for the confusion. The heat effect actually measures the speed-level 
of the heat, not the type of heat.  We added some additional
explanations in the first paragraph of section 3.2 to make it clear what the
venue and heat effect refer to. We did not want to call it a ``race effect" as we
were worried that may be interpreted to mean the race of the athlete.  We did
not think it would be informative to  add and effect for individual runner's
average ability as many of observations in the data come from runners
\jy{It's the number of runners with 1 data point that determines how
  hard the athlete effect can be estimated. How many runners had only 1
  data point?}
with very few (1-3) data points, so taking an average of such a small sample may
not be informative, especially if there are outliers or an athlete had a bad
start.
\eds{let's revisit this again after objective 2 analyses are set}


\begin{comment}
Otherwise, I think the manuscript could be improved by streamlining the
presentation of the organizing material like the problem statements and theory.
The literature review currently reads like an itemized list of all the relevant
studies; revising to focus on the specific arguments the paper hopes to make
could help improve clarity. As it is, I am not entirely sure if the paper is
specifically trying to test a hypothesis offered by others (e.g. the sensors
were calibrated in some way to lead to faster reaction times) or just present a
general framework for studying track and field down the road. I believe the
former is stronger and of more interest than the latter, so making clear the
purpose would help.
\end{comment}  

We appreciate the feedback, which was echoed by the second
reviewer. To address these concerns, we revised the introduction to
better structure our arguments. We streamlined the literature review
to focus only on studies directly relevant to our analysis and
clarified the paper’s two main objectives: (1) identifying
inconsistencies in the 2022 reaction times and (2) assessing whether
the 0.1-second threshold is fair. We avoided speculating on sensor
calibration or implicating Seiko due to a lack of direct evidence, and
instead, we provide general recommendations for World Athletics while
noting that the unusually fast reaction times in 2022 remain
unexplained.


\begin{comment}
Altogether, I see a lot of promising work here and think it would generally
benefit from expanded scope and analysis.
\end{comment}

Thank you for the positive feedback. We expanded both the rank
comparison and the GLMM sections with additional data to strengthen our
analysis. These enhancements support our findings of an anomaly in
2022 and highlight that the 0.1-second reaction time threshold lacks a
foundation in formal statistical evidence.
\eds{let's revisit this again after objective 2 analyses are set}


\subsection*{To Reviewer 2}


\begin{comment}
The paper’s topic is very important, but has significant issues with the writing
quality and statistical rigor. Right now, the manuscript reads more like report
than a paper. The text lacks significant direction, and does not explain the
goals of the study until the 4th page. Even then, “checking for abnormalities”
is very vague.
\end{comment}


We have revised the Introduction and Discussion sections to clearly
outline the goals of the study. Both reviewers noted issues with
organization, so we streamlined the manuscript to emphasize the two
main objectives: (1) identifying inconsistencies in the 2022 reaction
times and (2) assessing whether the 0.1-second threshold is fair. We
removed unrelated sections to keep the focus on these central
points. Regarding the rank comparison and timing devices at the 2022
Championships, we intentionally used cautious language, as there is no
evidence to claim a miscalibration or fault in Seiko’s timing
devices. To avoid potential legal risks, we noted the unusually fast
reaction times in 2022 without making unsubstantiated claims. Instead,
we allow readers to interpret the underlying cause of the anomaly
based on the presented data.


\begin{comment}
Concerns about statistical tests:

I am not convinced that the rank-based comparison test is the best choice here.
There are two questions: 1) Was the venue for the 2022 championships faster than
usual? 2) Was the final heat for the 2022 championships faster than usual?

If you are trying to answer question (1), you should include reaction times from
every spring event, not just the hurdles. If you are trying to answer question
2, why not do the following Monte Carlo test:

1. Sample a single reaction time for each athlete in the final.
2. Calculate the mean reaction time for the simulated final.
3. Compute the probability of seeing the observed average reaction time deviate
as much as it did in the 2022 Championships.

This test seems better than a rank sum test, as ranks do not capture the
differences between times.

\end{comment}

Thank you for the feedback. We are attempting to address question~(1)
and have expanded our analysis to include reaction times from
additional sprint events at the World Championships, including both
men and women's 100-meter data. This broader dataset helps provide a
more comprehensive assessment of whether the venue in 2022 was
unusually fast. 

Please see our second response to Reviewer 1 for additional 
comments relating to longer sprint events (200-meter or longer), 
and why these were not also included in our analyses.



\begin{comment}
I am also not convinced that the GLMM methods used for evaluating the
probability of disqualification are valid. The tests use data of reaction times
from performances that were NOT disqualified.  The data is therefore truncated
with no samples from the “left” or “disqualified” tail. This means that any
conclusions about the probability of a reaction time falling below this
threshold is purely extrapolation from the distributional assumptions. The
authors use a gamma distribution based on its fit to the data they have. In my
opinion, the choice of a gamma distribution is not sufficiently justified to
make extrapolating claims about the probability mass in the upsampled tail. I am
not convinced there is enough data to make a strong argument here, especially
when the previous literature on reaction time uses different distributions.
\end{comment}

Thank you for raising these points. Regarding the exclusion of
disqualified runners, we chose not to include athletes with negative
reaction times, as these indicate an attempt to predict the starting
gun rather than a true reaction. Negative reaction times do not align
with the purpose of the GLMM analysis, which aims to evaluate the
feasibility of the 0.1-second reaction threshold. Including negative
times would introduce results where the reaction occurred before the
gun fired, making them unsuitable for this analysis.


For the approximately 20 disqualified athletes with positive reaction
times, we examined the impact of including them in the analysis. The
probability of observing a reaction time below 0.1 seconds increased
\jy{Are these based on the expanded dataset or the original dataset?}
slightly from 0.0029 to 0.0039, with similar parameter estimates for
the random effects. Given these results, we opted to include these
observations in the dataset.


Distribution: \jy{need to check R package gamlss.}


\jy{Find these references and cite them:
Sprint Start Regulation in Athletics: A Critical Review.
Milloz M, Hayes K, Harrison AJ.
Sports Med. 2021 Jan;51(1):21-31. doi: 10.1007/s40279-020-01350-4.
PMID: 33125639 Review.
Reaction time aspects of elite sprinters in athletic world championships.
Tønnessen E, Haugen T, Shalfawi SA.
J Strength Cond Res. 2013 Apr;27(4):885-92. doi: 10.1519/JSC.0b013e31826520c3.
PMID: 22739331
}

\begin{comment}
The paper also mentions another claim that I think would be worth investigating:
Devon Allen’s reaction times might be faster due to innate ability. I think it
would be nice to show that his average reaction time faster, and that this
difference is statistically significant. It would also be nice to see how Devon
Allen’s DIFFERENCE in reaction time compares to the differences of the other
competitors (relative to previous heats, or averages, or whatever). If Devon
Allen’s time improved anomalously in the final heat, this would suggest a false
start. Based on the fact that he recorded a .101 reaction time earlier, I am
guessing he did not improve anomalously.  
\end{comment}

Thank you for this suggestion. Unfortunately, comprehensive data on
Devon Allen's reaction times is not readily available. We gathered as
much data as we could find online, but there is insufficient
information from lower-level meets, as reaction times are typically
only recorded at major competitions (e.g., national and world
championships). Given the limited data, we could not conduct a formal
statistical analysis of his reaction times. However, we have added a
brief discussion of this issue in paragraph~???] of the Discussion Section.


\begin{comment}
A point that is not sufficiently emphasized is that the track officials consider
low reaction times to be false starts because an athlete can ANTICIPATE a start
faster than they can REACT to the starting gun. I think this is important to
discuss so that a general audience understands why an athlete might be
disqualified even through they started running after the race began.  
\end{comment}

We added additional explanations to address this in the introductions section.
\jy{Give paragraph number for specific locations}

\begin{comment}
I have no idea how to interpret the numbers displayed in Table 2. These
need to be made interpretable, or they add nothing to the paper.
\end{comment}

The nomenclature for the greek variables in Table 2 are defined in the GLMM
subsection of the methods section (3.2).
\eds{let's revisit this again after objective 2 analyses are set}

\begin{comment}
Line 127: Is there a reason you are commenting on the difficult of data
gathering? I am not sure it adds much.
\end{comment}

Yes, the comments about the difficulty of data gathering are meant to demonstrate
that we worked hard to find as much data as we could and, as a note to World
Athletics (track and field governing body), that they need to do a better job
at data standardization.  Currently the races on their website do not include
reaction times, which meant that we had to look in alternative places to perform
the analyses that we did.  The data we found from national level meets in 2022
was difficult to come by as it required searching for every country's championship
results individually and when we did find it, it was often in the native language
making it harder to understand and interpret.

\begin{comment}
Line 141: “We compare the times” - do you mean reaction times?
\end{comment}

Yes, this has been rephrased for clarification.

\begin{comment}
Figure 3 is extremely inefficient. Maybe show the deltas on one plot? I'm not
sure a plot is even needed. What is the goal here? If you want to show that 2022
is anomalous you need to show where it stands in the distribution. Trying to
show that 2022 is anomalous based on a shift in the calculated venue effects
seems very roundabout.
\end{comment}

We included this plot to show the venue effect for each year and to visually
demonstrate how 2022 compares to other years.  We added additional comments
about the probability of observing an extreme venue effect to provide
quantitative data supporting our argument.
\eds{let's revisit this again after objective 2 analyses are set}


\bibliographystyle{apalike}
\bibliography{citations}
\end{document}
