\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{natbib}
\usepackage{hyperref}

\usepackage{listings}
\usepackage{rotating, graphicx}
\graphicspath{{./}, {./image/}}
\usepackage{booktabs, natbib}
% \usepackage{breakurl}
% \usepackage [english]{babel}
\usepackage{amsmath, amsbsy, amsthm, epsfig, epsf, psfrag, graphicx, 
amssymb, enumerate}
\usepackage{bm}
\usepackage{multirow, multicol}

\usepackage[dvipsnames]{color}
\definecolor{darkblue}{rgb}{0.1, 0.2, 0.6}

\newcommand{\jy}[1]{\textcolor{red}{JY: #1}}
\newcommand{\eds}[1]{\textcolor{blue}{(EDS: #1)}}
\newcommand{\mc}[1]{\textcolor{green}{(MC: #1)}}

\sloppy

% \usepackage{csquotes}
% \usepackage [autostyle, english = american]{csquotes}
% \MakeOuterQuote{"}

% \usepackage{bibentry}
\newenvironment{comment}%
{\begin{quotation}\noindent\small\it\color{darkblue}\ignorespaces%
}{\end{quotation}}


\begin{document}

\begin{center}
  {\Large\bf Response to the Comments}
\end{center}

We extend our gratitude to the Editor and Associate Editor for 
granting us the opportunity to revise this manuscript. We also want to
express our appreciation to the reviewer for their valuable comments. 


The manuscript has been revised accordingly with the most notable change being 
the addition of Section 5 (Classroom Implementation). We believe this revision 
has enhanced the both the quality and utility of this paper.


Point-by-point responses to the comments are as follows, with the
comments quoted in \emph{\color{darkblue} italic and blue}.


\subsection*{To Reviewer 1}


\jy{What is ``the first point?''  Please quote everything from the
  reviewer, including the positive comments.}

\begin{comment}
To address the first point, the paper relies on descriptive statistics, ranked
tests, and the results of a set of GLMMs. The descriptive data analysis lends
credence to the authors' argument that the reaction times at the 2022 World
Championships was faster than at any of the relevant comparisons. The rank test
appears to be set up correctly and I believe the authors are interpreting the
results correctly. Similarly, I believe the GLMM results are arrived at
correctly given the provided code.

The paper attempts to answer the second question by applying the GLMMs they
already fit. To do so, it presents simulations from the fitted GLMM. It then
uses the simulated results to estimate the probability of observing reaction
times below a set of thresholds. I think it does a good job of contextualizing
these in terms of the number of races per an occurrence.
\end{comment}


Thank you for these encouraging comments.  


\begin{comment}
However, I do believe the analysis to answer this first question could be
substantially improved. First, the paper only presents results for men running
the 110 meter hurdles. Women also competed at these events as they later
acknowledge in the discussion section. Why not use data from those competitors?
(There is a suggestion that the systematic effect seen at the 2022 World
Championships for men would not/did not appear for women because they may have
slower reaction times. No analysis is provided to support that though. Could
that be provided?) Similarly, other sprinting events were held using the same
block-sensor technology. Were similar patterns present in the 100-meter and
200-meter dashes? What about in the longer 400-meter dash and 400-meter hurdle
races? I think expanding the sample here would yield helpful insights into the
systematic nature of the problem the paper is trying to investigate. These
expanded samples could improve both the ranked-test results and the GLMM results
and improve the generalizability of the conclusions.
\end{comment}


Thank you for these suggestions, we were able to expand the scope of our data
by including results from the men's and women's 100 meter dash.  We considered
adding additional sprinting events such as the 200 meter dash but
when we included a term for type of event in our model the coefficient on this
event term was significant for the 200 meter dash for both men's and women's
data. The coefficient was not signficant when we included the 100 meter dash
results. This is not particularly suprising as athletes who compete in the longer
events may not have as good of a start as those in the 100
meter events because reaction time plays a much smaller role in the outcome of
the race. While it is common for amateur and collegiate athletes to compete in
multiple sprinting events, it seems reasonable that a world championship 100
meter runner may be only a very good 200 meter runner.  We are trying to
estimate the probabilty of observing a extreme reaction time to determine
whether 0.1 seconds is fair but if we include data from competitions with slower
reaction times, then 0.1 seconds is going to be more extreme.  To answer later
thoughts about looking at all sprinting events, we observed boxplots and what we
found were that reaction times in longer sprinting events were much more stable
than in the 100 meter dash and hurdle and thus any insights would likely not be
informative to questioning whether 0.1 seconds is a fair barrier or if athletes
in those events had faster reaction times in 2022.  This follows the conventional
wisdom that athletes are more focuesed on not false starting at the start of the
longer races than they are on getting a perfect start.

\jy{At the end of each reply, we need to state what changes we made to
  the manuscript with their specific locations. The explanation here
  (the exclusion of 200m dash) should be included in the paper as well.}

\begin{comment}
Relatedly, I believe the GLMM results could be improved by considering a few
more factors. Currently, the GLMMs regress reaction time onto models that only
contains predictors for year and whether or not an observation comes from a
preliminary heat or a final (both as random intercepts). It strikes me that the
authors may also want to account for confounding factors such as the overall
speed-level of the heat (especially relative to that point in time) and the
speed of the given runner relative to the others in the heat, as these factors
are likely to inform whether a runner tries to push their reaction to the limit
or not and are potentially correlated with year and race type, biasing the
results. Accounting for these additional features (in addition to expanding the
analysis) should help clarify if there was a specific difference attributable to
2022.
\end{comment} 


The heat effect measures the speed-level of the heat.  We added some additional
explanations to make it clear what the venue and heat effect refer to. We did
not want to call it a "race effect" as we were worried that may be interpreted
to mean the race of the athlete.  We did not think it would be informative to 
add and effect for individual runner's average ability as the majority of
observations in the data come from runners with very few (1-3) data points,
so taking an average of such a small sample may not be informative, especially
if there are outliers or an athlete had a bad start.


\begin{comment}
Otherwise, I think the manuscript could be improved by streamlining the
presentation of the organizing material like the problem statements and theory.
The literature review currently reads like an itemized list of all the relevant
studies; revising to focus on the specific arguments the paper hopes to make
could help improve clarity. As it is, I am not entirely sure if the paper is
specifically trying to test a hypothesis offered by others (e.g. the sensors
were calibrated in some way to lead to faster reaction times) or just present a
general framework for studying track and field down the road. I believe the
former is stronger and of more interest than the latter, so making clear the
purpose would help.
\end{comment}  

The second reviewer shared a similar sentiment about not effectively
presenting ideas so we we made improvements to the introduction section to try
and more clearly present our ideas.  We shortened the literature review to only
cite papers that were actually of interest to the paper and tried to clearly
define the two purposes of the paper: to decide of 0.1 seconds is fair, and to
\jy{The order is reversed in the paper.}
identify inconsistensies with the 2022 reaction times. We try to be precise in
our language as we do not have enough evidence to conclude that the sensors were
calibrated differently, or that Seiko (who make the timing devices) is at fault
for the 2022 reaction times being inexplicably faster. Thus we make general
recommendations for World Athletics and note that the reaction times in 2022
were unusually fast with no clear reason.

\begin{comment}
Altogether, I see a lot of promising work here and think it would generally
benefit from expanded scope and analysis.
\end{comment}


Thank you for these encouraging words. \jy{State what expansions we
  have done.}

\subsection*{Reviewer2}


\begin{comment}
The paper’s topic is very important, but has significant issues with the writing
quality and statistical rigor. Right now, the manuscript reads more like report
than a paper. The text lacks significant direction, and does not explain the
goals of the study until the 4th page. Even then, “checking for abnormalities”
is very vague.
\end{comment}


We have re-worked the introduction and discussion sections of the paper to more
clearly outline the goals of the paper.  The organization of the paper was
something that both reviewers commented on so we did our best to try and
streamline the two key points of the paper: to decide of 0.1 seconds is fair,
and to identify inconsistensies with the 2022 reaction times. With these two
points emphasized we tried to remove sections that did not support these central
ideas.  In regards to the language surrounding the rank comparison text and the
timing device at the 2022 Championships we are intentionally vague as we do not
have evidence to make a stronger claim.  For example, we cannot claim that the
timing device was faulty as miscalibrated as there is no public information
available about that.  We do not want to overstep and put ourselves or the
publication at risk of defamation claims from Seiko because we called their
devices faulty when they are not.  Instead we suggest to the reader that 2022
was an unusually fast year and comment that there is no explanation as to why
athletes improve reaction times over the span of a few months and let the reader
decide what they think is the underlying cause of the faster reaction times.


\begin{comment}
Concerns about statistical tests:

I am not convinced that the rank-based comparison test is the best choice here.
There are two questions: 1) Was the venue for the 2022 championships faster than
usual? 2) Was the final heat for the 2022 championships faster than usual?

If you are trying to answer question (1), you should include reaction times from
every spring event, not just the hurdles. If you are trying to answer question
2, why not do the following Monte Carlo test:

1. Sample a single reaction time for each athlete in the final.
2. Calculate the mean reaction time for the simulated final.
3. Compute the probability of seeing the observed average reaction time deviate
as much as it did in the 2022 Championships.

This test seems better than a rank sum test, as ranks do not capture the
differences between times.

\end{comment}

We are attempting to answer question 1 and have included reaction times from
additional sprinting events from World Championships.  We hypothesized that
as the length of the race increased, reaction time would be less impactful and
thus not as important. We started by adding data for the 100 meter dash and that
is the most similar event in terms of length to the 110 meter hurdles.  When we
added an additional variable to the model based on whether the observation came
from a dash event or hurdles event the coefficient was not significant.  An 
ANOVA test likewise produced a not signficant coefficient indicating to us that
it seems reasonable to pool the 100 meter dash and 110 meter hurdles.  We
hypothesized that longer sprinting events (200 meter dash, 400 meter dash, 400
meter hurdles) would be more difficult to add as those are longer races where
athletes reactions times are not as important to their overall time in the race.
When we repeat the procedure we did for the 100 meter dash, now looking at data
that included the 100 meter dash, 110 meter hurdles, and the 200 meter dash we
found that the coefficient on event type was signficant, and a p value of 0.01586.
When we peformed a TukeyHSD test to compare the times in the three categories:
100 meter dash, 110 meter hurdles, 200 meter dash, we found a p-value of
0.0020625 comparing the means of the 200 meter dash and the 110 meter hurdles
and a p-value of 0.0000174 comparing the means of the 100 meter dash and the 200
meter dash.  This indicated to us that the reaction times for the 200 meter were
too slow to fit into our study on extreme reaction times and thus we chose to
exclude 200 meter data.


\begin{comment}
I am also not convinced that the GLMM methods used for evaluating the
probability of disqualification are valid. The tests use data of reaction times
from performances that were NOT disqualified.  The data is therefore truncated
with no samples from the “left” or “disqualified” tail. This means that any
conclusions about the probability of a reaction time falling below this
threshold is purely extrapolation from the distributional assumptions. The
authors use a gamma distribution based on its fit to the data they have. In my
opinion, the choice of a gamma distribution is not sufficiently justified to
make extrapolating claims about the probability mass in the upsampled tail. I am
not convinced there is enough data to make a strong argument here, especially
when the previous literature on reaction time uses different distributions.
\end{comment}
Athletes may be disqualified based on PED use, and athletes may not finish a race
due to injury, thus we did not consider these times.  However, it does seem
reasonable to include times from people who were disqualified based on their
reaction time.

In terms of the choice of distribution, Brosnan and Harrison used a exponentially
modified gaussian distribution using athletes sex, ruling periods, competition
rounds. The article is now behind a pay wall.
\jy{Not a reason for not citing it. We can still find pdf online.}

\jy{Using log-normal distribution for the reaction times is quite easy
  to do. You just take log of the reaction times, and then model them
  in a GLMM with Guassian family. I think we did this, and decided it
  was not good perhaps from the residual qq plots. Please find them
  and add a discussion into the paper.}

\jy{This references has been cited 31 times. Some of these are closely
  related to our topic and should be cited as appropriate.}

\begin{comment}
The paper also mentions another claim that I think would be worth investigating:
Devon Allen’s reaction times might be faster due to innate ability. I think it
would be nice to show that his average reaction time faster, and that this
difference is statistically significant. It would also be nice to see how Devon
Allen’s DIFFERENCE in reaction time compares to the differences of the other
competitors (relative to previous heats, or averages, or whatever). If Devon
Allen’s time improved anomalously in the final heat, this would suggest a false
start. Based on the fact that he recorded a .101 reaction time earlier, I am
guessing he did not improve anomalously.  
\end{comment}

Unfortunately data such as this is not easy to come by.  We found as much as we
could online, but there is simply not enough data to justify a formal analysis
of his reaction times across lower level meets.  Many track and field races do
not record data on reaction times until at the very high level (national
and world championship).  Simply put, reaction times are not heavily researched
and thus the data material in insufficient.
\jy{We have added a discussion in paragraph ??? of the Discussion Section.}

\jy{Every point we cannot answer needs to have some response reflected
  in discussions in the manuscript.}

\begin{comment}
A point that is not sufficiently emphasized is that the track officials consider
low reaction times to be false starts because an athlete can ANTICIPATE a start
faster than they can REACT to the starting gun. I think this is important to
discuss so that a general audience understands why an athlete might be
disqualified even through they started running after the race began.  
\end{comment}

We added additional explanations to address this in the introductions section.
\jy{Give paragraph number for specific locations}

\begin{comment}I have no idea how to interpret the numbers displayed in Table 2. These
need to be made interpretable, or they add nothing to the paper.
\end{comment}

The nomenclature for the greek variables in Table 2 are defined in the GLMM
subsection of the methods section (3.2)

\begin{comment}
Line 127: Is there a reason you are commenting on the difficult of data
gathering? I am not sure it adds much.
\end{comment}

Yes, the comments about the difficulty of data gathering are meant to demostrate
that we worked hard to find as much data as we could and as a note to World
Athletics (track and field governing body) that they need to do a better job
at data standardization.  Currently the races on their website do not include
reaction times, which meant that we had to look in alternative places to perform
the analysis that we did.  The data we found from national level meets in 2022
was difficult to come by as it required searching for every country's championship
results individually and when we did find it, it was often in the native language
making it harder to understand and interpret.

\begin{comment}
Line 141: “We compare the times” - do you mean reaction times?
\end{comment}

Yes, this has been resolved.

\begin{comment}
Figure 3 is extremely inefficient. Maybe show the deltas on one plot? I'm not
sure a plot is even needed. What is the goal here? If you want to show that 2022
is anomalous you need to show where it stands in the distribution. Trying to
show that 2022 is anomalous based on a shift in the calculated venue effects
seems very roundabout.
\end{comment}

We included this plot to show the venue effect for each year and to visually
demonstrate how 2022 compares to other years.  We added additional comments
about the probability of observing an extreme venue effect to provide
quantitative data supporting our argument.



\subsection*{Associate Editor}
\jy{Put this section before the reviewers.}

\begin{comment}
I encourage you to consider the issues raised by the reviewers carefully. I have
little additional material to add, other than to emphasize the need to
re-organize the manuscript to more clearly identify the key goals of the work at
the start, and to provide a more concise and focused presentation of the key
findings.
\end{comment}

\begin{comment}
We have taken additional steps to streamline the manuscript and enhance the
presentation of our work. Thank you for your time and we appreciate re-considering
our submission.
\end{comment}

%\bibliographystyle{chicago}
%\bibliography{citations}
\end{document}
