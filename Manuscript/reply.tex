\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{natbib}
\usepackage{hyperref}

\usepackage{listings}
\usepackage{rotating, graphicx}
\graphicspath{{./}, {./image/}}
\usepackage{booktabs, natbib}
% \usepackage{breakurl}
% \usepackage [english]{babel}
\usepackage{amsmath, amsbsy, amsthm, epsfig, epsf, psfrag, graphicx, 
amssymb, enumerate}
\usepackage{bm}
\usepackage{multirow, multicol}

\usepackage[dvipsnames]{color}
\definecolor{darkblue}{rgb}{0.1, 0.2, 0.6}

\newcommand{\jy}[1]{\textcolor{red}{JY: #1}}
\newcommand{\eds}[1]{\textcolor{blue}{(EDS: #1)}}
\newcommand{\mc}[1]{\textcolor{green}{(MC: #1)}}

\sloppy

% \usepackage{csquotes}
% \usepackage [autostyle, english = american]{csquotes}
% \MakeOuterQuote{"}

% \usepackage{bibentry}
\newenvironment{comment}%
{\begin{quotation}\noindent\small\it\color{darkblue}\ignorespaces%
}{\end{quotation}}


\begin{document}

\begin{center}
  {\Large\bf Response to the Comments}
\end{center}

We extend our gratitude to the Editor and Associate Editor for 
granting us the opportunity to revise this manuscript. We also want to
express our appreciation to the reviewer for their valuable comments. 


The manuscript has been revised accordingly with the most notable change being 
the addition of Section 5 (Classroom Implementation). We believe this revision 
has enhanced the both the quality and utility of this paper.


Point-by-point responses to the comments are as follows, with the
comments quoted in \emph{\color{darkblue} italic and blue}.


\subsection*{To Reviewer}


\begin{comment}
To address the first point, the paper relies on descriptive statistics, ranked
tests, and the results of a set of GLMMs. The descriptive data analysis lends
credence to the authors' argument that the reaction times at the 2022 World
Championships was faster than at any of the relevant comparisons. The rank test
appears to be set up correctly and I believe the authors are interpreting the
results correctly. Similarly, I believe the GLMM results are arrived at
correctly given the provided code.

The paper attempts to answer the second question by applying the GLMMs they
already fit. To do so, it presents simulations from the fitted GLMM. It then
uses the simulated results to estimate the probability of observing reaction
times below a set of thresholds. I think it does a good job of contextualizing
these in terms of the number of races per an occurrence.
\end{comment}


Thank you for these encouraging comments.  


\begin{comment}
However, I do believe the analysis to answer this first question could be
substantially improved. First, the paper only presents results for men running
the 110 meter hurdles. Women also competed at these events as they later
acknowledge in the discussion section. Why not use data from those competitors?
(There is a suggestion that the systematic effect seen at the 2022 World
Championships for men would not/did not appear for women because they may have
slower reaction times. No analysis is provided to support that though. Could
that be provided?) Similarly, other sprinting events were held using the same
block-sensor technology. Were similar patterns present in the 100-meter and
200-meter dashes? What about in the longer 400-meter dash and 400-meter hurdle
races? I think expanding the sample here would yield helpful insights into the
systematic nature of the problem the paper is trying to investigate. These
expanded samples could improve both the ranked-test results and the GLMM results
and improve the generalizability of the conclusions.
\end{comment}


One of the reasons why we did not include data from other sprinting evetns is
because we wanted to ground the article in Devon Allen's story and to be about
the hurdles events.  Athletes who compete in the longer events such as 400 meters
may not have as good of a start as those in the 100 meter events because reaction
time plays a much smaller role in the outcome of the race. While it is common
for amateur and collegiate athletes to compete in multiple sprinting events, it
seems reasonable that a world championship 100 meter runner may be only a top 20
200 meter runner.  We are trying to estimate the probabilty of observing a extreme
reaction time to determine whether 0.1 seconds is fair but if we include data
from competitions with slower reaction times, then 0.1 seconds is going to be
more extreme.


\begin{comment}
Relatedly, I believe the GLMM results could be improved by considering a few
more factors. Currently, the GLMMs regress reaction time onto models that only
contains predictors for year and whether or not an observation comes from a
preliminary heat or a final (both as random intercepts). It strikes me that the
authors may also want to account for confounding factors such as the overall
speed-level of the heat (especially relative to that point in time) and the
speed of the given runner relative to the others in the heat, as these factors
are likely to inform whether a runner tries to push their reaction to the limit
or not and are potentially correlated with year and race type, biasing the
results. Accounting for these additional features (in addition to expanding the
analysis) should help clarify if there was a specific difference attributable to
2022.
\end{comment} 


The heat effect measures the speed-level of the heat.  We added some additional
explanations to make it clear what the venue and heat effect refer to. We did
not want to call it a "race effect" as we were worried that may be interpreted
to mean the race of the athlete.


\begin{comment}
Otherwise, I think the manuscript could be improved by streamlining the
presentation of the organizing material like the problem statements and theory.
The literature review currently reads like an itemized list of all the relevant
studies; revising to focus on the specific arguments the paper hopes to make
could help improve clarity. As it is, I am not entirely sure if the paper is
specifically trying to test a hypothesis offered by others (e.g. the sensors
were calibrated in some way to lead to faster reaction times) or just present a
general framework for studying track and field down the road. I believe the
former is stronger and of more interest than the latter, so making clear the
purpose would help.

\end{comment}  
We do not have enough evidence to conclude that the sensors were calibrated
differently, so thus we make general recommendations for World Athletics.

\begin{comment}
Altogether, I see a lot of promising work here and think it would generally
benefit from expanded scope and analysis.
\end{comment}


Thank you for these encouraging words.

\subsection*{Reviewer2}


\begin{comment}
The paper’s topic is very important, but has significant issues with the writing
quality and statistical rigor. Right now, the manuscript reads more like report
than a paper. The text lacks significant direction, and does not explain the
goals of the study until the 4th page. Even then, “checking for abnormalities”
is very vague.

\end{comment}


We can restructure the paper but doesn't the abstract mention the goals of the
paper? I suppose the introduction is really more of a background section.


\begin{comment}
Concerns about statistical tests:

I am not convinced that the rank-based comparison test is the best choice here.
There are two questions: 1) Was the venue for the 2022 championships faster than
usual? 2) Was the final heat for the 2022 championships faster than usual?

If you are trying to answer question (1), you should include reaction times from
every spring event, not just the hurdles. If you are trying to answer question
2, why not do the following Monte Carlo test:

1. Sample a single reaction time for each athlete in the final.
2. Calculate the mean reaction time for the simulated final.
3. Compute the probability of seeing the observed average reaction time deviate
as much as it did in the 2022 Championships.

This test seems better than a rank sum test, as ranks do not capture the
differences between times.

\end{comment}

We are attempting to answer question 1 and have included reaction times from
additional sprinting events from World Championships.  We hypothesized that
as the length of the race increased, reaction time would be less impactful and
thus not as important. We started by adding data for the 100 meter dash and that
is the most similar event in terms of length to the 110 meter hurdles.  When we
added an additional variable to the model based on whether the observation came
from a dash event or hurdles event the coefficient was not significant.  An 
ANOVA test likewise produced a not signficant coefficient indicating to us that
it seems reasonable to pool the 100 meter dash and 110 meter hurdles.  We
hypothesized that longer sprinting events (200 meter dash, 400 meter dash, 400
meter hurdles) would be more difficult to add as those are longer races where
athletes reactions times are not as important to their overall time in the race.
When we repeat the procedure we did for the 100 meter dash, now looking at data
that included the 100 meter dash, 110 meter hurdles, and the 200 meter dash we
found that the coefficient on event type was signficant, and a p value of 0.01586.
When we peformed a TukeyHSD test to compare the times in the three categories:
100 meter dash, 110 meter hurdles, 200 meter dash, we found a p-value of
0.0020625 comparing the means of the 200 meter dash and the 110 meter hurdles
and a p-value of 0.0000174 comparing the means of the 100 meter dash and the 200
meter dash.  This indicated to us that the reaction times for the 200 meter were
too slow to fit into our study on extreme reaction times and thus we chose to
exclude 200 meter data.


\begin{comment}
I am also not convinced that the GLMM methods used for evaluating the
probability of disqualification are valid. The tests use data of reaction times
from performances that were NOT disqualified.  The data is therefore truncated
with no samples from the “left” or “disqualified” tail. This means that any
conclusions about the probability of a reaction time falling below this
threshold is purely extrapolation from the distributional assumptions. The
authors use a gamma distribution based on its fit to the data they have. In my
opinion, the choice of a gamma distribution is not sufficiently justified to
make extrapolating claims about the probability mass in the upsampled tail. I am
not convinced there is enough data to make a strong argument here, especially
when the previous literature on reaction time uses different distributions.
\end{comment}
Athletes may be disqualified based on PED use, and athletes may not finish a race
due to injury, thus we did not consider these times.  However, it does seem
reasonable to include times from people who were disqualified based on their
reaction time.

In terms of the choice of distribution, Brosnan and Harrison used a exponentially
modified gaussian distribution using athletes sex, ruling periods, competition
rounds. The article is now behind a pay wall.


\begin{comment}
The paper also mentions another claim that I think would be worth investigating:
Devon Allen’s reaction times might be faster due to innate ability. I think it
would be nice to show that his average reaction time faster, and that this
difference is statistically significant. It would also be nice to see how Devon
Allen’s DIFFERENCE in reaction time compares to the differences of the other
competitors (relative to previous heats, or averages, or whatever). If Devon
Allen’s time improved anomalously in the final heat, this would suggest a false
start. Based on the fact that he recorded a .101 reaction time earlier, I am
guessing he did not improve anomalously.  
\end{comment}

Unfortunately data such as this is not easy to come by.  We found as much as we
could online, but there is simply not enough data to justify a formal analysis
of his reaction times across lower level meets.

\begin{comment}
A point that is not sufficiently emphasized is that the track officials consider
low reaction times to be false starts because an athlete can ANTICIPATE a start
faster than they can REACT to the starting gun. I think this is important to
discuss so that a general audience understands why an athlete might be
disqualified even through they started running after the race began.  
\end{comment}

We added additional explanations to address this in the introductions section.

\begin{comment}I have no idea how to interpret the numbers displayed in Table 2. These
need to be made interpretable, or they add nothing to the paper.
\end{comment}

The nomenclature for the greek variables in Table 2 are defined in the GLMM
subsection of the methods section (3.2)

\begin{comment}
Line 127: Is there a reason you are commenting on the difficult of data
gathering? I am not sure it adds much.
\end{comment}

Yes, the comments about the difficulty of data gathering are meant to demostrate
that we worked hard to find as much data as we could and as a note to World
Athletics (track and field governing body) that they need to do a better job
at data standardization.  Currently the races on their website do not include
reaction times, which meant that we had to look in alternative places to perform
the analysis that we did.  The data we found from national level meets in 2022
was difficult to come by as it required searching for every country's championship
results individually and when we did find it, it was often in the native language
making it harder to understand and interpret.

\begin{comment}
Line 141: “We compare the times” - do you mean reaction times?
\end{comment}

Yes, this has been resolved.

\begin{comment}
Figure 3 is extremely inefficient. Maybe show the deltas on one plot? I'm not
sure a plot is even needed. What is the goal here? If you want to show that 2022
is anomalous you need to show where it stands in the distribution. Trying to
show that 2022 is anomalous based on a shift in the calculated venue effects
seems very roundabout.
\end{comment}

We included this plot to show the venue effect for each year and to visually
demonstrate how 2022 compares to other years.  We added additional comments
about the probability of observing an extreme venue effect to provide
quantitative data supporting our argument.



\subsection*{Associate Editor}
\begin{comment}
I encourage you to consider the issues raised by the reviewers carefully. I have
little additional material to add, other than to emphasize the need to
re-organize the manuscript to more clearly identify the key goals of the work at
the start, and to provide a more concise and focused presentation of the key
findings.
\end{comment}

\begin{comment}
We have taken additional steps to streamline the manuscript and enhance the
presentation of our work. Thank you for your time and we appreciate re-considering
our submission.
\end{comment}

%\bibliographystyle{chicago}
%\bibliography{citations}
\end{document}
