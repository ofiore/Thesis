---
title: "ReactionBarrierAnalysis"
author: "Owen Fiore"
date: "2024-11-28"
output: html_document
---

The objective of this document is to allow other researchers to replicate our
results in regards to the GAMLSS section of the paper.
# Main Analysis
The first thing we need is our data.  We create the `times` data to be the full
data, and will create relevant subsets depending on what we need to fit.

```{r}
times <- read.csv("../Data/rxntime.csv")
colnames(times) <- c("Venue", "Type", "Time", "RxnTime", "Gender", "Heat", "Event")
```


The first data set is the men's dash and hurdles which we will denote as `dhm`.
The first filter we apply is to look at data from semifinals and finals, as
previous papers have suggested that reaction times in the heats may not be 
as fast due to less competitive heats.  We cannot include times from athletes
who did not start (DNS) as they do not have reaction times, but we do consider
times from athletes who were disqualified (This is further examined in the
supplemental analysis).  We cannot fit negative times with our gamma model and
negative reaction times make little practical sense, so we remove those as well.
Additionally we need to select the 100 meter dash and 110 meter hurdles as
there are more events (200 meter dash) included in the data but not included in
this analysis.  Lastly we convert `Venue` and `Heat` to be factor variables as
those are used as random effects in the model.

An important part of the paper is examining the results of excluding 2022 from
the analysis to see the impact 2022 had.  Thus we are going to be replicating
much of the same methods for the modeling phrase but need to exclude 2022 from
the dataset.
```{r}
library(tidyverse)
dhm <- times |>
  filter(Type == "F" | Type == "S") |>
  filter(Gender == "M") |>
  filter(Time != "DNS") |>
  filter(RxnTime > 0) |>
  filter(Event == "100 Dash" | Event == "110 Hurdles") |>
  mutate(Venue = as.factor(Venue), Heat = as.factor(Heat))

#Only difference between these two dataframes is the filter removing 2022
dhm_no2022 <- times |>
  filter(Type == "F" | Type == "S") |>
  filter(Gender == "M") |>
  filter(Time != "DNS") |>
  filter(RxnTime > 0) |>
  filter(Event == "100 Dash" | Event == "110 Hurdles") |>
  filter(Venue != 2022) |>
  mutate(Venue = as.factor(Venue), Heat = as.factor(Heat))
```
Let's visualize the data.
```{r}
boxplot_df <- dhm |>
  mutate(Venue = as.numeric(as.character(Venue)))
library(ggplot2)
ggplot(boxplot_df, aes(x = Venue, y = RxnTime, group = Venue)) +
  geom_boxplot() +
  labs(x = "Year", y = "Reaction Time (s)") +
       scale_y_continuous(limits = c(0.05, 0.275),
                            breaks = seq(0.05, 0.275, 0.025)) +
  expand_limits(y = 0.1) + scale_x_continuous(limits = c(1998,2024),
                                              breaks = seq(1999, 2024, 2))
```
We see that the 2022 boxplot is lower than any other year.  What is particularly
interesting is that Allen's 0.099 reaction time that led to his disqualification
does not appear as an outlier in 2022, it is just the minimum value.  Compared
to in 1999, where a value right around 0.100 was an outlier.


We considered many families of models, and formula structures within the
generalized Gamma but thought that the results from the `gg3b` game strong
results.  The first term corresponds to the $\mu$ term of the model, which is
a random effect for `Venue`. $\sigma$ contains a random effect for `Heat`.
```{r}
gg3b <- gamlss(RxnTime ~ random(Venue), sigma.formula = ~ random(Heat),
               data = dhm, family = GG, control = gamlss.control(n.cyc = 40))

gg3b_no2022 <- gamlss(RxnTime ~ random(Venue), sigma.formula = ~ random(Heat),
                      data = dhm_no2022, family = GG, control = gamlss.control(n.cyc = 40))

```

We can explore some information about this model and replicate the results
presented in Table 2 of the paper by running the code below.
```{r}
summary(gg3b)
cat("tau_v or std dev of venue effect: ", gg3b$mu.coefSmo[[1]]$sigb, "\n")
cat("tau_h or std dev of heat effect: ", gg3b$sigma.coefSmo[[1]]$sigb[1], "\n")
```

And now for the model excluding 2022
```{r}
summary(gg3b)
cat("tau_v or std dev of venue effect: ", gg3b_no2022$mu.coefSmo[[1]]$sigb, "\n")
cat("tau_h or std dev of heat effect: ", gg3b_no2022$sigma.coefSmo[[1]]$sigb[1], "\n")
```

One of the key findings of this section is that by including 2022 in the model,
the standard deviation of the venue effects increases from 0.043 to 0.058. This
demonstrates that the reaction times from 2022 helped contribute to more
variability in the range of venue effects.

The code below plots the venue effects from the model to visually see the
differences that result by including 2022.
```{r}
library(gridExtra)
venue_effects <- as.data.frame(gg3b$mu.coefSmo[[1]]$coef)
colnames(venue_effects) <- c("Effect Value")

venue_plot <- ggplot(venue_effects, aes(x = rownames(venue_effects),
                                               y = `Effect Value`)) +
  geom_point() + 
  labs(x = "Venue", y = "Venue Effect")+
  scale_y_continuous(limits = c(-0.15, 0.1))


## Second plot
venue_effects_no2022 <- as.data.frame(gg3b_no2022$mu.coefSmo[[1]]$coef)
venue_effects_no2022["2022", ] <- 1 #Arbitrary number out of range of y scale so
#that the x axis line up

colnames(venue_effects_no2022) <- c("Effect Value")

venue_plot_no2022 <- ggplot(venue_effects_no2022,
                                   aes(x = rownames(venue_effects_no2022),
                                       y = `Effect Value`)) +
  geom_point() + 
  labs(x = "Venue", y = "Venue Effect") +
  scale_y_continuous(limits = c(-0.15, 0.1))

#Put it together
grid.arrange(venue_plot, venue_plot_no2022, ncol = 1)
```
In the above figure, the top graph corresponds to the venue effects from `gg3b`,
and the bottom graph represents the venue effects from `gg3b_no2022` which is
why there is no 2022 venue effect for 2022.  There is some year to year
variability in the graphs, with differences in venue effects in 2007 and 2011
occuring potentially due to the change in disqualification rules that were
implemented by World Athletics.  The venue effects from 2015 to 2023 were
very consistent with values very close to 0, with the exception of 2022 which
had a venue effect of roughly -0.13.


We also need to evaluate how well the `gg3b` model fit the data, and we look
at the standardized residuals to do so.

```{r}
library(qqconf)
qq_conf_plot(residuals(gg3b))
```

We see that the model fits the data extremely well considering the size of the
data is roughly 775 points.  Thus this seems like a strong model choice that
will produce good results.

```{r}
qq_conf_plot(residuals(gg3b_no2022))
```
The residual plot when the model is fit without 2022 is very similar with few
noticeable differences.


Now that we have chosen a model and it passed necessary specifications, we can
use it to simulate times and determine how extreme a 0.1 second reaction time
barrier is.  The function `simfit` draws 10,000,000 samples from a probability
distribution determined in the last line of the function, which draws from a
generalized Gamma distribution parameterized by `mu`, `sigma`, and `nu`.

```{r}
simfit <- function(model, n = 10000000) {
    set.seed(1)
  
    #Extract standard deviation of venue and heat effect
    sd_Venue <- model$mu.coefSmo[[1]]$sigb
    sd_Venue_heat <- model$sigma.coefSmo[[1]]$sigb[1]
    
    #Calculate mu, sigma, nu with coefficients and standard deviation of random effects
    mu <- exp(model$mu.coefficients[1] + rnorm(n, mean = 0 , sd = sd_Venue))
    sigma <- exp(model$sigma.coefficients[1] + rnorm(n, mean = 0 , sd = sd_Venue_heat))
    nu <- model$nu.coefficients[1]
    
    #Generate the distribution
    rGG(n, mu = mu, sigma = sigma, nu = nu)
}
```
Using the distribution returned in the last line of code, we then want to
examine the probability of observing a reaction time less than 0.1 seconds.  We
do this as a way of measuring whether the 0.1 barrier is fair.  If we see a
large probability, this indicates that 0.1 seconds is too strict a barrier and
World Athletics should consider changes.

Now we can fit our distribution and assign it to `samplefit` and repeat for
the model and thus distribution without 2022.

```{r}
samplefit <- simfit(gg3b)
samplefit_no2022 <- simfit(gg3b_no2022)
```

We use `mean(samplefit < 0.10)` to determine the proportion of the distribution
less than 0.1 and repeat this for 0.09 and 0.08 to assess how extreme those
would be.  These probabilities can be found in table 3 of the paper.
```{r}

mean(samplefit < 0.10)
mean(samplefit_no2022 < 0.10)
cat("\n")
mean(samplefit < 0.09)
mean(samplefit_no2022 < 0.09)
cat("\n")
mean(samplefit < 0.08)
mean(samplefit_no2022 < 0.08)
```
We see that in every comparison, it is more likely to observe an extreme reaction
time when 2022 is included in the analysis.

Perhaps the more interesting aspect of this analysis, is the ability to
recommend a new reaction time barrier based on the distribution.  Thus we want
to know the quantile that certain important probabilities would have.  If World
Athletics wanted to quantitatively create a reaction time barrier what they
should do is first decide on what percentage of times they should disqualify
for being unreasonable.  We are going to look at 1 in every 100, 1000, and 10000
observations and the result is what the reaction barrier should be.  The results
below are presented in table 4 of the paper.

```{r}
quantile(samplefit, c(.01, .001, .0001))
cat("\n")
quantile(samplefit_no2022, c(.01, .001, .0001))
```
We see that by excluding 2022, the suggested reaction time barrier is higher
and more strict.  this analysis is important and interesting to repeat in several
years to see what the effect of future World Championships will be on the barrier.
If there are more years like 2022, then World Athletics should take steps to
change the reaction time barrier because that indicates that athletes are
getting faster and thus reaction times under 0.1 seconds are no longer looked
at as the athlete predicting the gun, but rather that they have fast reflexes.


# Supplemental Analysis

We are going to see what happens when we pool men's and women's data together.
We sill need to separate by year but will have 3 analyses instead of 6.  As a
result of the larger data set we are going to run the permutation tests at a
size of $n = 100,000$ rather than $n = 1,000,000$ as the code takes several
hours to run otherwise.  The asymptotic results are all highly statistically
significant, and with the larger data sets, the results from the asymptotic
tests should be of higher quality.

### 2019 vs 2022

Need to talk about results after running code

Data setup
```{r}
men_2019 <- read.csv("../Data/Clusrank2019vs2022.csv")
colnames(men_2019) <- c("Time", "Athlete", "Year", "Event")

women_2019 <- read.csv("../Data/Clusrank2019vs2022Womens.csv")
colnames(women_2019) <- c("Time", "Athlete", "Year", "Event")

women_2019$Athlete <- women_2019$Athlete + 34 #Correction for unique athlete identifier

all_2019 <- rbind(men_2019, women_2019)
```

And now we run the tests
```{r}
set.seed(1)
library(clusrank)
clusWilcox.test(Time, group=Year, cluster = Athlete, data = all_2019,
                method = "ds")

clusWilcox.test(Time, group=Year, cluster = Athlete, data = all_2019,
                method = "ds",
                exact = TRUE, B = 100000)
```
### 2022 National vs International

Data setup
```{r}
men_2022 <- read.csv("../Data/ClusrankNatvsWorld.csv")
colnames(men_2022) <- c("Time", "Athlete", "Year", "Event")


women_2022 <- read.csv("../Data/ClusrankNatvsWorldWomens.csv")
colnames(women_2022) <- c("Time", "Athlete", "Year", "Event")

women_2022$Athlete <- women_2022$Athlete + 17 #Correction for unique athlete identifier

all_2022 <- rbind(men_2022, women_2022)
```

And now we run the tests.

```{r}
set.seed(1)
library(clusrank)
clusWilcox.test(Time, group=Year, cluster = Athlete, data = all_2022,
                method = "ds")

clusWilcox.test(Time, group=Year, cluster = Athlete, data = all_2022,
                method = "ds",
                exact = TRUE, B = 100000)
```
### 2022 vs 2023

```{r}
men_2023 <- read.csv("../Data/Clusrank2022vs2023.csv")
colnames(men_2023) <- c("Time", "Athlete", "Year", "Event")

women_2023 <- read.csv("../Data/Clusrank2022vs2023Womens.csv")
colnames(women_2023) <- c("Time", "Athlete", "Year", "Event")

women_2023$Athlete <- women_2023$Athlete + 45 #Correction for unique athlete identifier

all_2023 <- rbind(men_2023, women_2023)
```

Now we run the tests.
```{r}
set.seed(1)
library(clusrank)
clusWilcox.test(Time, group=Year, cluster = Athlete, data = all_2023,
                method = "ds")

clusWilcox.test(Time, group=Year, cluster = Athlete, data = all_2023,
                method = "ds",
                exact = TRUE, B = 100000)
```


By pooling together all events within the year comparison, we find highly
significant results, suggesting that on average, the athletes who competed in
2022 had faster reaction times.

### Women's Gamlss
We decided to separate women's results after numerous papers suggested that
men and women have differing reaction times, but we still thought it was important
to investigate what an appropriate reaction time barrier was for women.  The
women's data is very similar to the men's, but there is not data from 1999
available for women and the women compete in the 100 meter hurdle instead of the
110 meter hurdle.  We are going to replicate many of the same methods used above
for the men's results.

We read in the women's data by filtering `Gender` and `Event` differently.
```{r}
library(tidyverse)
dhw <- times |>
  filter(Type == "F" | Type == "S") |>
  filter(Gender == "F") |>
  filter(Time != "DNS") |>
  filter(RxnTime > 0) |>
  filter(Event == "100 Hurdles" | Event == "100 Dash")
dhw <- dhw[- which.min(dhw$RxnTime), ] #We remove the minimum time as it is an
#extreme outlier as we want an accurate prediction of the left tail
```

Lets visualize the women's data.  This appears as Figure 1 in the supplemental
file.
```{r}
library(ggplot2)
ggplot(dhw, aes(x = Venue, y = RxnTime, group = Venue)) +
  geom_boxplot() +
  labs(x = "Year", y = "Reaction Time (s)") +
       scale_y_continuous(limits = c(0.05, 0.3),
                            breaks = seq(0.05, 0.3, 0.025)) +
  expand_limits(y = 0.1) + scale_x_continuous(limits = c(2000,2024),
                                              breaks = seq(2001, 2024, 2))
```
We see that 2022 appears as a low outlier, but perhaps not as extreme as for the
men's data.  The women's data also seems to be more stable than the men's with
fewer venue to venue differences.


Now we are ready to fit the women's model.  We tested several types of generalized
Gamma models, including those different from the men's model, and found that
this model, which is the female equivalent to the men's best model, was the best
fit.
```{r}
dhw <- dhw|>
  mutate(Venue = as.factor(Venue), Heat = as.factor(Heat))
gg3b0.w <- gamlss(RxnTime ~ random(Venue), sigma.formula = ~ random(Heat),
                  data = dhw, family = GG, control = gamlss.control(n.cyc = 40))
```

```{r}
summary(gg3b0.w)
cat("tau_v or std dev of venue effect: ", gg3b0.w$mu.coefSmo[[1]]$sigb, "\n")
cat("tau_h or std dev of heat effect: ", gg3b0.w$sigma.coefSmo[[1]]$sigb[1], "\n")
```
We see that the heat and venue effects are statistically significant and
contribute positively to the model.  We are also going to look at the residuals
to see how well the data is fit.
```{r}
library(qqconf)
qq_conf_plot(residuals(gg3b0.w))
```
Although this fit is not as strong as the men's data, we still found it to be
acceptable and it was the best of the several women's models that we looked at.

As the structure of the model remains the same, we are able to reuse the `simfit`
code developed above in order to examine what the women's disqualification
barrier should look like.

```{r}
samplefit_w <- simfit(gg3b0.w)

mean(samplefit_w < 0.10)
cat("\n")
mean(samplefit_w < 0.09)
cat("\n")
mean(samplefit_w < 0.08)

```

```{r}
quantile(samplefit_w, c(.01, .001, .0001))
```

It is worth noting that these suggested times are slower than the one's for the
men's data.  Thus, men and women are not currently held to the same standard
if men are more likely to react quickly than women and if they share the 0.1
barrier.